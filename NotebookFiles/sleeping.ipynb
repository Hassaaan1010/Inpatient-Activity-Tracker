{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "# import time\n",
    "from stopwatch import Stopwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719925754.855629  467100 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1719925754.858801  467144 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) HD Graphics 4400 (HSW GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1719925754.995276  467141 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1719925755.030450  467140 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/home/hassaan/.local/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2658044695854187\n",
      "-0.25944849848747253\n",
      "-0.260187566280365\n",
      "-0.2820696532726288\n",
      "-0.2862708270549774\n",
      "-0.3547796607017517\n",
      "-0.3833526074886322\n",
      "-0.5184555649757385\n",
      "-0.56525719165802\n",
      "-0.5193840265274048\n",
      "-0.48375946283340454\n",
      "-0.4821338653564453\n",
      "-0.4643954336643219\n"
     ]
    }
   ],
   "source": [
    "# CAMERA MEDIA PIPING\n",
    "state = None  # can be standing sitting lying\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow(\"Mediapipe feed: \", frame)\n",
    "        # time.sleep(1)\n",
    "        if True:\n",
    "            # recolor image to rgb from cv2 default (bgr)\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # make detection and store in result\n",
    "            # writeable flag is unset before processing to improve performance and avoid unintended write ops.\n",
    "            # frame is read and processed and the data is written to results.\n",
    "            results = pose.process(frame)\n",
    "\n",
    "            # convert back to cv2 default bgr\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            shoulderStats = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "            hipStats = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "            ankleStats = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "\n",
    "            shoulder = [\n",
    "                shoulderStats.x,\n",
    "                shoulderStats.y,\n",
    "            ]\n",
    "            hip = [\n",
    "                hipStats.x,\n",
    "                hipStats.y,\n",
    "            ]\n",
    "            ankle = [\n",
    "                ankleStats.x,\n",
    "                ankleStats.y,\n",
    "            ]\n",
    "            print(shoulder[1])\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,  # output\n",
    "            results.pose_landmarks,  # passing landmarks\n",
    "            mp_pose.POSE_CONNECTIONS,  # passing landmark connections\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Mediapipe feed: \", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(\n",
    "        a[1] - b[1], a[0] - b[0]\n",
    "    )\n",
    "    angle = np.abs(radians * 180 / np.pi)\n",
    "\n",
    "    if angle > 180:\n",
    "        return 360 - angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for a person to be laying the difference in their head x and foot x should be small while head y and foot y is small.\n",
    "# the reverse would mean that they are standing.\n",
    "# this all assumes a condition where the camera is viewing the person from the side.\n",
    "# what if the person has to be viewed from the front?\n",
    "# the head\n",
    "# z value is unreliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719991111.566771  472576 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1719991111.574791  522920 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) HD Graphics 4400 (HSW GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1719991111.825821  522913 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1719991111.862904  522915 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/home/hassaan/.local/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# CAMERA MEDIA PIPING\n",
    "lying = Stopwatch(2)\n",
    "sitting = Stopwatch(2)\n",
    "state = None  # can be \"standing\", \"sitting\", \"lying\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow(\"Mediapipe feed: \", frame)\n",
    "        # time.sleep(1)\n",
    "        if True:\n",
    "            # recolor image to rgb from cv2 default (bgr)\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # make detection and store in result\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # convert back to cv2 default bgr\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            shoulderStats = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "            hipStats = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "            ankleStats = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "\n",
    "            shoulder = [\n",
    "                shoulderStats.x,\n",
    "                shoulderStats.y,\n",
    "            ]\n",
    "            hip = [\n",
    "                hipStats.x,\n",
    "                hipStats.y,\n",
    "            ]\n",
    "            ankle = [\n",
    "                ankleStats.x,\n",
    "                ankleStats.y,\n",
    "            ]\n",
    "\n",
    "            angle = int(calculateAngle(shoulder, hip, ankle))\n",
    "\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                str(angle),\n",
    "                tuple(np.multiply(hip, [640, 480]).astype(int)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        if state != \"lying\" and angle > 140:\n",
    "            lying.start()\n",
    "            sitting.stop()\n",
    "            state = \"lying\"\n",
    "\n",
    "        if state == \"lying\" and angle < 140:\n",
    "            sitting.start()\n",
    "            lying.stop()\n",
    "            state = \"sitting\"\n",
    "\n",
    "        cv2.rectangle(image, (0, 0), (350, 50), (245, 117, 16), -1)\n",
    "\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"ANGLE\",\n",
    "            (15, 12),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(angle),\n",
    "            (15, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"STATE\",\n",
    "            (90, 12),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            state,\n",
    "            (90, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"Down time\",\n",
    "            (150, 12),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(int(lying.duration)),\n",
    "            (150, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,  # output\n",
    "            results.pose_landmarks,  # passing landmarks\n",
    "            mp_pose.POSE_CONNECTIONS,  # passing landmark connections\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Mediapipe feed: \", image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
